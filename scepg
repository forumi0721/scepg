#!/usr/bin/env python3
# -*- coding: utf-8 -*-

#print function
from __future__ import print_function

###Library Config
__USE_BS = True
__USE_LXML = True
__DEBUG = True

###Import(static)
import sys
import os
import argparse
try:
    import configparser
except ImportError:
    import ConfigParser as configparser
import socket
import time
import datetime
try:
    from urllib import quote,unquote
except ImportError:
    from urllib.parse import quote,unquote
try:
    import urllib.request as request
except ImportError:
    import urllib2 as request
import http.client, urllib.parse
import re
import json
from subprocess import call
#for python2
if sys.version_info[0] < 3:
    from io import open
    reload(sys)
    sys.setdefaultencoding('utf-8')
    __USE_LXML = False
    import HTMLParser
    htmlparser = HTMLParser.HTMLParser()
else:
    import html as htmlparser
###Import(dynamic)
#Check BeautifulSoup
if __USE_BS:
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        __USE_BS = False
#Check lxml
if __USE_LXML:
    try:
        from lxml import etree
        import lxml.builder
    except ImportError:
        __USE_LXML = False
if not __USE_LXML:
    import xml.etree.ElementTree as ET
    from xml.dom import minidom

####SSL
#import ssl
#
#ctx = ssl.create_default_context()
#ctx.check_hostname = False
#ctx.verify_mode = ssl.CERT_NONE
#request.urlopen(url, context=ctx)

###Global Constant
CONFIG_FILE = "tvchannel.conf"
LIST_FILE = "tvchannel.list"
LIST_FILE_STATIC = "tvchannel.list.static"

___START_TIME = time.time()


def progressLog(progress, totalCount):
    totalLength = 10
    progressLength = int((progress / totalCount) * totalLength)

    printLog(" -> Progress : [%s%s] (%d/%d)" % ("#" * progressLength, "-" * (totalLength - progressLength), progress, totalCount), end = "\r", flush = True)

    if progress >= totalCount:
        printLog("")

def progressCount(progress):
    printLog(" -> Count : %d" % progress, end = "\r", flush = True)

def printLog(log, end = "\n", flush = False, error = False, file = None):
    if file is None:
        out = None
        if args.v or error:
            out = sys.stderr
        else:
            out = sys.stdout

        out.write("%s%s" % (log, end))
        if flush:
            out.flush()
    else:
        for out in file:
            if sys.version_info[0] < 3:
                out.write(unicode("%s%s" % (log, end)))
            else:
                out.write("%s%s" % (log, end))
            if flush:
                out.flush()

def readConfig():
    global channel_list
    global retrieve_days
    global output_xml
    global output_xml_pretty_print
    global output_socket
    global post_proc
    global post_proc_args

    configFilePath = None

    printLog("==> Read config file")

    if args.f:
        if not os.path.isfile(args.f):
            printLog(" -> Cannot found config file")
            exit(1)
        configFilePath = args.f
    elif os.path.isfile(CONFIG_FILE):
        configFilePath = CONFIG_FILE
    elif os.path.isfile("/usr/local/etc/" + CONFIG_FILE):
        configFilePath = "/usr/local/etc/" + CONFIG_FILE
    elif os.path.isfile("/var/lib/scepg/" + CONFIG_FILE):
        configFilePath = "/var/lib/scepg/" + CONFIG_FILE
    elif os.path.isfile("/etc/" + CONFIG_FILE):
        configFilePath = "/etc/" + CONFIG_FILE
    else:
        printLog(" -> Cannot found config file")
        exit(1)

    config = configparser.RawConfigParser()
    config.optionxform = str
    config.read(configFilePath)

    printLog(" -> Config file : " + configFilePath)
    printLog(" -> python major version : " + str(sys.version_info[0]))
    if __USE_BS:
        printLog(" -> BeautifulSoup : Yes")
    else:
        printLog(" -> BeautifulSoup : No")
    if __USE_LXML:
        printLog(" -> LXML : Yes")
    else:
        printLog(" -> LXML : No")

    progressLog(0, 4)
    if not config.has_section("channel_list"):
        printLog("")
        printLog(" -> Config file not contains channel_list section")
        exit(1)

    progressLog(1, 4)

    try:
        channel_list = config.items("channel_list")
    except configparser.Error:
        printLog("")
        printLog(" -> Config file not contains channel_list section")
        exit(1)

    progressLog(2, 4)

    #retrieve_days = config.getint("defaults", "retrieve_days", fallback=1)
    try:
        retrieve_days = config.getint("defaults", "retrieve_days")
    except configparser.NoOptionError:
        retrieve_days = 1
    #output_xml = config.get("defaults", "output_xml", fallback="")
    try:
        output_xml = config.get("defaults", "output_xml")
    except configparser.NoOptionError:
        output_xml = ""
    #output_xml_pretty_print = config.getboolean("defaults", "output_xml_pretty_print", fallback=False)
    try:
        output_xml_pretty_print = config.getboolean("defaults", "output_xml_pretty_print")
    except configparser.NoOptionError:
        output_xml_pretty_print = False
    #output_socket = config.get("defaults", "output_socket", fallback="")
    try:
        output_socket = config.get("defaults", "output_socket")
    except configparser.NoOptionError:
        output_socket = ""
    #post_proc = config.get("defaults", "post_proc", fallback="")
    try:
        post_proc = config.get("defaults", "post_proc")
    except configparser.NoOptionError:
        post_proc = ""
    #post_proc_args = config.get("defaults", "post_proc_args", fallback="")
    try:
        post_proc_args = config.get("defaults", "post_proc_args")
    except configparser.NoOptionError:
        post_proc_args = ""

    progressLog(3, 4)

    if args.b:
        output_xml_pretty_print = True

    if not args.v and output_xml == "" and output_socket == "":
        printLog("")
        printLog("-v 또는 output_xml, output_socket 값이 설정되지 않았습니다.")
        exit(1)

    progressLog(4, 4)

    printLog("==> Done.", end = "\n\n")

def printXml():
    printLog("==> Print XML")

    if __USE_LXML:
        print(etree.tostring(xml, pretty_print = output_xml_pretty_print, xml_declaration = True, encoding = "UTF-8", doctype = "<!DOCTYPE tv SYSTEM \"xmltv.dtd\">").decode("utf-8"))
    else:
        if output_xml_pretty_print == True:
            print(minidom.parseString(ET.tostring(xml, encoding = "utf-8", method = "xml")).toprettyxml(indent = " "))
        else:
            print(ET.tostring(xml, encoding = "utf-8", method = "xml").decode("utf-8"))

    printLog("==> Done.", end = "\n\n")

def writeXml():
    xml_list = output_xml.split(" ")
    xml_list = [x for x in xml_list if x != '']
    socket_list = output_socket.split(" ")
    socket_list = [x for x in socket_list if x != '']
    if not xml_list and not socket_list:
        return

    printLog("==> Write XML")
    progress = 0
    progressLog(progress, len(xml_list) + len(socket_list))

    for xml_config in xml_list:
        f = None
        try:
            f = open(xml_config, "w", encoding='utf8')
            if __USE_LXML:
                f.writelines(etree.tostring(xml, pretty_print = output_xml_pretty_print, xml_declaration = True, encoding = "UTF-8", doctype = "<!DOCTYPE tv SYSTEM \"xmltv.dtd\">").decode("utf-8"))
            else:
                if output_xml_pretty_print:
                    f.writelines(minidom.parseString(ET.tostring(xml, encoding = "utf-8", method = "xml")).toprettyxml(indent = " "))
                else:
                    f.writelines(ET.tostring(xml, encoding = "utf-8", method = "xml").decode("utf-8"))
        except Exception as e:
            printLog("")
            printLog(" -> Unknown error : %s (%s)" % (xml_config, e.args[0]), error = True)

        if f is not None:
            f.close()

        progress += 1
        progressLog(progress, len(xml_list) + len(socket_list))

    for socket_config in socket_list:
        match_tcp = re.match("tcp:(.*):(.*)", socket_config)
        xml_socket = None
        connect = False
        if match_tcp:
            xml_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            try:
                xml_socket.connect((match_tcp.group(1), int(match_tcp.group(2))))
            except Exception as e:
                printLog(" -> Unknown error : %s (%s)" % (socket_config, e.args[0]), error = True)
            else:
                connect = True
        else:
            xml_socket = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
            try:
                xml_socket.connect(socket_config)
            except Exception as e:
                printLog(" -> Unknown error : %s (%s)" % (socket_config, e.args[0]), error = True)
            else:
                connect = True

        if connect:
            if __USE_LXML:
                xml_socket.send(etree.tostring(xml, pretty_print = False, xml_declaration = True, encoding = "UTF-8", doctype = "<!DOCTYPE tv SYSTEM \"xmltv.dtd\">"))
            else:
                xml_socket.send(ET.tostring(xml, encoding = "utf-8", method = "xml"))

        if xml_socket is not None:
            xml_socket.close()

        progress += 1
        progressLog(progress, len(xml_list) + len(socket_list))

    printLog("==> Done.", end = "\n\n")

def writeSocket():
    socket_list = output_socket.split(" ")
    socket_list = [x for x in socket_list if x != '']
    if not socket_list:
        return

    printLog("==> Write Socket")
    progress = 0
    progressLog(progress, len(socket_list))

    f_xml = open("xmltv.xml", "r")

    for socket_config in socket_list:
        match_tcp = re.match("tcp:(.*):(.*)", socket_config)
        xml_socket = None
        connect = False
        if match_tcp:
            xml_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            try:
                xml_socket.connect((match_tcp.group(1), int(match_tcp.group(2))))
            except Exception as e:
                printLog(" -> Unknown error : %s (%s)" % (socket_config, e.args[0]), error = True)
            else:
                connect = True
        else:
            xml_socket = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
            try:
                xml_socket.connect(socket_config)
            except Exception as e:
                printLog(" -> Unknown error : %s (%s)" % (socket_config, e.args[0]), error = True)
            else:
                connect = True

        if connect:
            xml_socket.send(str.encode(f_xml.read(), encoding="utf-8"))

        if xml_socket is not None:
            xml_socket.close()

        progress += 1
        progressLog(progress, len(socket_list))

    f_xml.close()

    printLog("==> Done.", end = "\n\n")

def generateXmlRoot():
    global xml

    printLog("==> Genreate XML Root")

    progressLog(0, 1)

    if __USE_LXML:
        xml = lxml.builder.ElementMaker().tv()
        xml.set("source-info-name", "stonecold.kr")
        xml.set("generator-info-name", "forumi0721")
        xml.set("generator-info-url", "mailto:forumi0721@gmail.com")
    else:
        xml = ET.Element("tv", {"source-info-name":"stonecold.kr", "generator-info-name":"forumi0721", "generator-info-url":"mailto:forumi0721@gmail.com"})

    progressLog(1, 1)

    printLog("==> Done.", end = "\n\n")

def generateXmlChannel():
    printLog("==> Generate XML Channels")

    progress = 0;
    progressLog(0, len(channel_list))

    for channel_config in channel_list:
        channel = channel_config[0].split(",")

        channel_id = channel[0]
        channel_name = channel[1]
        channel_icon = None
        if len(channel) == 3:
            channel_icon = "http://%s" % channel[2]

        if __USE_LXML:
            xml_channel = etree.Element("channel", id = "I%s.stonecold.kr" % channel_id)
            xml.append(xml_channel)

            xml_display_name1 = etree.Element("display-name")
            xml_display_name1.text = channel_name
            xml_channel.append(xml_display_name1)

            xml_display_name2 = etree.Element("display-name")
            xml_display_name2.text = "%s %s" % (channel_id, channel_name)
            xml_channel.append(xml_display_name2)

            xml_display_name3 = etree.Element("display-name")
            xml_display_name3.text = channel_id
            xml_channel.append(xml_display_name3)

            if channel_icon:
                xml_icon = etree.Element("icon", src = channel_icon)
                xml_channel.append(xml_icon)
        else:
            se_channel = ET.SubElement(xml, "channel", {"id":"I%s.stonecold.kr" % channel_id})

            se_channel_1 = ET.SubElement(se_channel, "display-name")
            se_channel_1.text = str(channel_name)

            se_channel_2 = ET.SubElement(se_channel, "display-name")
            se_channel_2.text = str("%s %s" % (channel_id, channel_name))

            se_channel_3 = ET.SubElement(se_channel, "display-name")
            se_channel_3.text = str(channel_id)

            if channel_icon:
                se_channel_icon = ET.SubElement(se_channel, "icon", {"src":channel_icon})

        progress += 1
        progressLog(progress, len(channel_list))

    printLog("==> Done.", end = "\n\n")

def generateXmlProgramme(dic_programme):
    if __USE_LXML:
        xml_programme = etree.Element("programme", channel = "I%s.stonecold.kr" % dic_programme["channel_id"], channel_name = dic_programme["channel_name"], channel_no = dic_programme["channel_id"], start = "%s +0900" % dic_programme["programme_start"], stop = "%s +0900" % dic_programme["programme_stop"])
        xml.append(xml_programme)

        xml_title = etree.Element("title", lang = "ko" )
        xml_title.text = dic_programme["title"]
        xml_programme.append(xml_title)

        #xml_sub_title = etree.Element("sub-title", lang = "ko" )
        #if "sub_title" in dic_programme:
        #    xml_sub_title.text = dic_programme["sub_title"]
        #else:
        #    xml_sub_title.text = dic_programme["title"]
        #xml_programme.append(xml_sub_title)

        #xml_desc = etree.Element("desc", lang = "ko" )
        #if "desc" in dic_programme:
        #    xml_desc.text = dic_programme["desc"]
        #else:
        #    xml_desc.text = dic_programme["title"]
        #xml_programme.append(xml_desc)

        if "episode_num" in dic_programme:
            xml_episode_num = etree.Element("episode-num", system = "onscreen" )
            xml_episode_num.text = dic_programme["episode_num"]
            xml_programme.append(xml_episode_num)

        if "category" in dic_programme:
            category = getCategory(dic_programme["category"])
            if category[0] != "":
                xml_category_ko = etree.Element("category", lang = "ko" )
                xml_category_ko.text = category[0]
                xml_programme.append(xml_category_ko)

            if category[1] != "":
                xml_category_en = etree.Element("category", lang = "en" )
                xml_category_en.text = category[1]
                xml_programme.append(xml_category_en)

        xml_language = etree.Element("language")
        xml_language.text = "ko"
        xml_programme.append(xml_language)

        if "rating" in dic_programme:
            xml_rating = etree.Element("rating", system = "VCHIP")
            xml_programme.append(xml_rating)
            xml_rating_value = etree.Element("value")
            xml_rating_value.text = dic_programme["rating"]
            xml_rating.append(xml_rating_value)

        xml_generate_source = etree.Element("generate-source", name = dic_programme["generate_source"])
        xml_programme.append(xml_generate_source)
    else:
        se_programme = ET.SubElement(xml, "programme", {"start":"%s +0900" % dic_programme["programme_start"], "stop":"%s +0900" % dic_programme["programme_stop"], "channel":"I%s.stonecold.kr" % dic_programme["channel_id"], "channel_no":str(dic_programme["channel_id"]), "channel_name":str(dic_programme["channel_name"])})

        se_title = ET.SubElement(se_programme, "title", {"lang":"ko"})
        se_title.text = dic_programme["title"]

        #se_sub_title = ET.SubElement(se_programme, "sub-title", {"lang":"ko"})
        #if "sub_title" in dic_programme:
        #    se_sub_title.text = dic_programme["sub_title"]
        #else:
        #    se_sub_title.text = dic_programme["title"]

        #se_desc = ET.SubElement(se_programme, "desc", {"lang":"ko"})
        #if "desc" in dic_programme:
        #    se_desc.text = dic_programme["desc"]
        #else:
        #    se_desc.text = dic_programme["title"]

        if "episode_num" in dic_programme:
            se_episode_num = ET.SubElement(se_programme, "episode-num", {"system":"onscreen"})
            se_episode_num.text = dic_programme["episode_num"]

        if "category" in dic_programme:
            category = getCategory(dic_programme["category"])
            if category[0] != "":
                se_category_ko = ET.SubElement(se_programme, "category", {"lang":"ko"})
                se_category_ko.text = category[0]

            if category[1] != "":
                se_category_en = ET.SubElement(se_programme, "category", {"lang":"en"})
                se_category_en.text = category[1]

        se_language = ET.SubElement(se_programme, "language")
        se_language.text = "ko"

        if "rating" in dic_programme:
            se_rating = ET.SubElement(se_programme, "rating", {"system":"VCHIP"})
            se_rating_value = ET.SubElement(se_rating, "value")
            se_rating_value.text = dic_programme["rating"]

        se_generate_source = ET.SubElement(se_programme, "generate-source", {"name":dic_programme["generate_source"]})

def generateXmlProgrammeUplus():
    channel_config = [[k, v] for k, v in channel_list if v[0] == "U"]
    if len(channel_config) <= 0:
        return

    generate_source = "http://www.uplus.co.kr/"
    base_url = "http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvSchedule.hpi?chnlCd={channel_code}&evntCmpYmd={date_ymd}"

    printLog("==> Generate Programmes (Uplus)")
    progress = 0
    progressLog(0, len(channel_config) * retrieve_days)

    for channel in channel_config:
        channel_id = channel[0].split(",")[0]
        channel_name = channel[0].split(",")[1]
        channel_code = channel[1].split(",")[1]

        dic_programme = {}

        for day in range(retrieve_days):
            download_date = (datetime.date.today() + datetime.timedelta(days = day))
            url = base_url.replace("{channel_code}", channel_code).replace("{date_ymd}", download_date.strftime("%Y%m%d"))

            f = None
            try:
                f = request.urlopen(url)
            except Exception as e:
                printLog(" -> error : %s (Uplus) - %s" % (url, e.args[0]), error = True)
                continue

            html = f.read().decode("cp949", "ignore")
            #UPLUS에서 제목을 제대로 안줌
            html = html.replace("<td class=\"title\"><", "<td class=\"title\">&lt;").replace("<td class=\"txtL\"><", "<td class=\"txtL\">&lt;")
            if __USE_BS:
                if __USE_LXML:
                    soup = BeautifulSoup(html, "lxml")
                else:
                    soup = BeautifulSoup(html, "html.parser")
                for tr in soup.select("tbody tr"):
                    row = 0
                    for td in tr.find_all("td"):
                        if row == 0:
                            if dic_programme:
                                if "programme_start" in dic_programme and "title" in dic_programme:
                                    dic_programme["programme_stop"] = "%s%s" % (download_date.strftime("%Y%m%d"), str(td.next_element).strip().replace(":", ""))
                                    generateXmlProgramme(dic_programme)

                            dic_programme.clear()
                            dic_programme["channel_id"] = channel_id
                            dic_programme["channel_name"] = channel_name
                            dic_programme["generate_source"] = generate_source
                            dic_programme["programme_start"] = "%s%s" % (download_date.strftime("%Y%m%d"), str(td.next_element).strip().replace(":", ""))
                        elif row == 1:
                            match_episode_num = re.search("^(.*)[\(|\[|<| ]([\d|,]+[회|강|부])[\)|\]|>| ]?$", td.next_element.strip())
                            if match_episode_num:
                                dic_programme["title"] = "%s (%s)" % (match_episode_num.group(1).strip(), match_episode_num.group(2).strip())
                                dic_programme["episode_num"] = match_episode_num.group(2).strip()
                            else:
                                dic_programme["title"] = td.next_element.strip()
                            #dic_programme["sub_title"] = dic_programme["title"]
                            #dic_programme["desc"] = dic_programme["title"]
                            match_rating = re.search(".*txtcon_grade_pg(\d+)\.gif.*", str(td.img), re.MULTILINE | re.DOTALL)
                            if match_rating:
                                dic_programme["rating"] = match_rating.group(1)
                        elif row == 2:
                            dic_programme["category"] = td.next_element.strip()
                        row += 1
            else:
                body = html.partition("<tbody>")[2].rpartition("</tbody>")[0]
                for programme in body.split("<tr>"):
                    match = re.search(".*<td>(\d+):(\d+)<\/td>.*<td class=\"title\">([^\n]*).*<\/td>(.*)<td>\W*(\w*)\W*<\/td>.*<\/tr>", programme, re.MULTILINE | re.DOTALL)
                    if match:
                        if dic_programme:
                            if "programme_start" in dic_programme:
                                dic_programme["programme_stop"] = "%s%s%s" % (download_date.strftime("%Y%m%d"), match.group(1), match.group(2))
                                generateXmlProgramme(dic_programme)

                        dic_programme.clear()
                        dic_programme["channel_id"] = channel_id
                        dic_programme["channel_name"] = channel_name
                        dic_programme["generate_source"] = generate_source
                        dic_programme["programme_start"] = "%s%s%s" % (download_date.strftime("%Y%m%d"), match.group(1), match.group(2))
                        match_episode_num = re.search("^(.*)[\(|\[|<| ]([\d|,]+[회|강|부])[\)|\]|>| ]?$", match.group(3).strip())
                        if match_episode_num:
                            dic_programme["title"] = "%s (%s)" % (match_episode_num.group(1).strip(), match_episode_num.group(2).strip())
                            dic_programme["episode_num"] = match_episode_num.group(2).strip()
                        else:
                            dic_programme["title"] = match.group(3).strip()
                        #dic_programme["sub_title"] = dic_programme["title"]
                        #dic_programme["desc"] = dic_programme["title"]
                        dic_programme["category"] = match.group(5)
                        match_rating = re.search(".*txtcon_grade_pg(\d+)\.gif.*", match.group(4), re.MULTILINE | re.DOTALL)
                        if match_rating:
                            dic_programme["rating"] = match_rating.group(1)

            f.close()
            progress += 1
            progressLog(progress, len(channel_config) * retrieve_days)

    printLog("==> Done.", end = "\n\n")

def generateXmlProgrammeSKB():
    channel_config = [[k, v] for k, v in channel_list if v[0] == "S"]
    if len(channel_config) <= 0:
        return

    generate_source = "http://m.skbroadband.com/"
    base_url = "http://m.skbroadband.com/content/realtime/Channel_List.do?key_depth1={key_depth1}&key_depth2={key_depth2}&key_depth3={date_ymd}"

    printLog("==> Generate Programmes (SKB)")
    progress = 0
    progressLog(0, len(channel_config) * retrieve_days)

    for channel in channel_config:
        channel_id = channel[0].split(",")[0]
        channel_name = channel[0].split(",")[1]
        channel_key1 = channel[1].split(",")[1]
        channel_key2 = channel[1].split(",")[2]

        dic_programme = {}

        for day in range(retrieve_days):
            download_date = (datetime.date.today() + datetime.timedelta(days = day))

            html = ""
            try:
                conn = http.client.HTTPConnection("m.skbroadband.com", 80)
                conn.request("GET", "/content/realtime/Channel_List.do?key_depth1=%s&key_depth2=%s&key_depth3=%s" % (channel_key1, channel_key2, download_date.strftime("%Y%m%d")))
                f = conn.getresponse()
                html = f.read().decode("cp949", "ignore")
                conn.close()
            except Exception as e:
                url = base_url.replace("{key_depth1}", channel_key1).replace("{key_depth2}", channel_key2).replace("{date_ymd}", download_date.strftime("%Y%m%d"))
                printLog(" -> error : %s (SKB) - %s" % (url, e.args[0]), error = True)
                continue

            #SKB에서 제목을 제대로 안줌
            html = html.replace("<p class \"tit\"><", "<p class \"tit\">&lt;").replace("<p class \"cont\"><", "<p class \"cont\">&lt;")
            if __USE_BS:
                if __USE_LXML:
                    soup = BeautifulSoup(html, "lxml")
                else:
                    soup = BeautifulSoup(html, "html.parser")
                for l in soup.select('li[class="list"]'):
                    start_time_l = l.select('p[class="time"]')
                    title_l = l.select('p[class="cont"]')

                    if title_l is None:
                        title_l = l.select('p[class="tit"]')

                    if start_time_l is None or title_l is None:
                        continue

                    programme_start = start_time_l[0].text.replace(":", "")
                    title = title_l[0].text.split("\n")[0]

                    if dic_programme:
                        if "programme_start" in dic_programme and "title" in dic_programme:
                            dic_programme["programme_stop"] = "%s%s" % (download_date.strftime("%Y%m%d"), programme_start)
                            generateXmlProgramme(dic_programme)

                            dic_programme.clear()
                    dic_programme["channel_id"] = channel_id
                    dic_programme["channel_name"] = channel_name
                    dic_programme["generate_source"] = generate_source
                    dic_programme["programme_start"] = "%s%s" % (download_date.strftime("%Y%m%d"), programme_start)
                    match_episode_num = re.search("^(.*)[\(|\[|<| ]([\d|,]+[회|강|부])[\)|\]|>| ]?$", title.strip())
                    if match_episode_num:
                        dic_programme["title"] = "%s (%s)" % (match_episode_num.group(1).strip(), match_episode_num.group(2).strip())
                        dic_programme["episode_num"] = match_episode_num.group(2).strip()
                    else:
                        dic_programme["title"] = title.strip()

            f.close()
            progress += 1
            progressLog(progress, len(channel_config) * retrieve_days)

    printLog("==> Done.", end = "\n\n")

#Deprecated
def generateXmlProgrammeNaver():
    channel_config = [[k, v] for k, v in channel_list if v[0] == "N"]
    if len(channel_config) <= 0:
        return

    generate_source = "http://www.naver.co.kr/"
    base_url = "https://search.naver.com/search.naver?query={channelCode}"

    printLog("==> Generate Programmes (Naver)")
    progress = 0
    progressLog(0, len(channel_config) * retrieve_days)

    for channel in channel_config:
        channel_id = channel[0].split(",")[0]
        channel_name = channel[0].split(",")[1]

        channel_code = channel[1].split(",")[1]

        url = base_url.replace("{channelCode}", quote(channel_code))

        f = None
        try:
            f = request.urlopen(url)
        except Exception as e:
            printLog(" -> error : %s (Naver) - %s" % (url, e.args[0]), error = True)
            continue
        html = f.read().decode("utf-8", "ignore")

        if not "var htInitDataForTvtimeSchedule = " in html:
            printLog(" -> Invalide Data")
            printLog("    Channel : " + channel)
            printLog("    URL : " + url)
            continue

        match = re.search("var htInitDataForTvtimeSchedule = ({.* ] }) </script>", html, re.MULTILINE | re.DOTALL)
        if match:
            js = json.loads(re.sub("/\*[^ ]*\*/", "", match.group(1)))
        else:
            js = json.loads(re.sub("/\*[^ ]*\*/", "", html.partition("var htInitDataForTvtimeSchedule = ")[2].rpartition(" ] } </script>")[0] + "] }"))

        seq_list = []
        for js_totalDates in js["totalDates"]:
            dt = datetime.date(int(js_totalDates[0:4]), int(js_totalDates[4:6]), int(js_totalDates[6:8]))
            if datetime.date.today() <= dt and (datetime.date.today() + datetime.timedelta(days = retrieve_days)) > dt:
                seq_list.append(js_totalDates)
            else:
                seq_list.append("")

        list_programme = []
        for js_schedule_time in js["schedules"]:
            seq = 0
            for js_schedules in js_schedule_time:
                seq = seq + 1
                if seq_list[seq - 1] != "" and js_schedules:
                    for js_schedule in js_schedules:
                        dic_programme = {}
                        dic_programme["channel_id"] = channel_id
                        dic_programme["channel_name"] = channel_name
                        dic_programme["generate_source"] = generate_source
                        dic_programme["programme_start"] = seq_list[seq - 1] + js_schedule["startTime"].replace(":", "")
                        #dic_programme["programme_stop"] =
                        if js_schedule["episode"] != "":
                            dic_programme["title"] = "%s (%s)" % (js_schedule["title"], js_schedule["episode"])
                            dic_programme["episode_num"] = js_schedule["episode"]
                        else:
                            match_episode_num = re.search("^(.*)[\(|\[|<| ]([\d|,]+[회|강|부])[\)|\]|>| ]?$", js_schedule["title"])
                            if match_episode_num:
                                dic_programme["title"] = "%s (%s)" % (match_episode_num.group(1).strip(), match_episode_num.group(2).strip())
                                dic_programme["episode_num"] = match_episode_num.group(2).strip()
                            else:
                                dic_programme["title"] = js_schedule["title"]
                        #dic_programme["sub_title"] = dic_programme["title"]
                        #dic_programme["desc"] = dic_programme["title"]
                        #dic_programme["category"] =
                        if js_schedule["grade"] != 0:
                            dic_programme["rating"] = str(js_schedule["grade"])

                        list_programme.append(dic_programme)

        dic_prev = {}
        for programme in sorted(list_programme, key=lambda k: k['programme_start']):
            if not dic_prev:
                dic_prev = programme
            else:
                dic_prev["programme_stop"] = programme["programme_start"]
                generateXmlProgramme(dic_prev)
                dic_prev = programme

        progress += retrieve_days
        progressLog(progress, len(channel_config) * retrieve_days)

    printLog("==> Done.", end = "\n\n")

#Deprecated
def generateXmlProgrammeEpg():
    channel_config = [[k, v] for k, v in channel_list if v[0] == "E"]
    if len(channel_config) <= 0:
        return

    generate_source = "http://www.epg.co.kr/"
    base_url = "http://epg.co.kr/php/guide/schedule_day_on.php?search_top_channel_group={top_channel_group}&old_top_channel_group={top_channel_group}&search_sub_channel_group={sub_channel_group}&old_sub_channel_group={sub_channel_group}&ymd={date_y-m-d}&{checkchannel}"
    base_url_epg_checkchannel = "checkchannel%5B{channel_code}%5D={channel_id}"

    printLog("==> Generate Programmes (EPG)")
    progress = 0
    progressLog(0, len(channel_config) * retrieve_days)

    download_list = []
    for channel in channel_config:
        top_channel_group = channel[1].split(",")[1]
        sub_channel_group = channel[1].split(",")[2]
        if [top_channel_group, sub_channel_group] not in download_list:
            download_list.append([top_channel_group, sub_channel_group])

    for download in download_list:
        top_channel_group = download[0]
        sub_channel_group = download[1]
        group_channel = [[k, v] for k, v in channel_config if v.split(",")[1] == top_channel_group and v.split(",")[2] == sub_channel_group]
        checkchannel = ""
        checkchannel_count = 0
        for channel in group_channel:
            channel_id = channel[0].split(",")[0]
            channel_name = channel[0].split(",")[1]
            channel_code = channel[1].split(",")[3]
            checkchannel = checkchannel + "&" + base_url_epg_checkchannel.replace("{channel_code}", channel_code).replace("{channel_id}", channel_id)
            checkchannel_count += 1
            if (checkchannel_count) % 5 == 0 or checkchannel_count == len(group_channel):
                for day in range(retrieve_days):
                    download_date = (datetime.date.today() + datetime.timedelta(days = day))
                    url = base_url.replace("{top_channel_group}", top_channel_group).replace("{sub_channel_group}", sub_channel_group).replace("{checkchannel}", checkchannel).replace("{date_y-m-d}", download_date.strftime("%Y-%m-%d"))

                    #with urllib.request.urlopen(url) as f:
                    f = None
                    try:
                        f = request.urlopen(url)
                    except Exception as e:
                        printLog(" -> error : %s (EPG) - %s" % (url, e.args[0]), error = True)
                        continue
                    match_preview = re.findall("(<td>.*Preview\(.*\).*</td>)", f.read().decode("cp949", "ignore").replace("<td>", "\n<td>").replace("</tr>", "\n</tr>"))
                    for preview in match_preview:
                        match_program = re.match(r".*Preview\('[^']*','(.*)','([^']*)','(\d*/\d* [^<]*)<br>~(\d*/\d* [^']*)','([^']*)','[^']*','[^']*'\).*", preview)
                        if match_program:
                            programme_channel_list = [k for k, v in group_channel if k.split(",")[0] == match_program.group(2)]
                            for programme_channel in programme_channel_list:
                                dic_programme = {}
                                dic_programme["channel_id"] = programme_channel.split(",")[0]
                                dic_programme["channel_name"] = programme_channel.split(",")[1]
                                dic_programme["generate_source"] = generate_source
                                match_episode_num = re.search("^(.*)[\(|\[|>| ]([\d|,]+[회|강|부])[\)|\]|>| ]?$", htmlparser.unescape(match_program.group(1)))
                                if match_episode_num:
                                    dic_programme["title"] = "%s (%s)" % (match_episode_num.group(1).strip().replace("\\'", "'"), match_episode_num.group(2).strip())
                                    dic_programme["episode_num"] = match_episode_num.group(2).strip()
                                else:
                                    dic_programme["title"] = htmlparser.unescape(match_program.group(1)).strip().replace("\\'", "'")
                                #dic_programme["sub_title"] = dic_programme["title"]
                                #dic_programme["desc"] = dic_programme["title"]
                                match_rating = re.search(".*schedule_(\d+)\.gif.*", preview)
                                if match_rating:
                                    dic_programme["rating"] = match_rating.group(1)
                                start_date = datetime.datetime.strptime("%d %s" % (download_date.year, match_program.group(3)), "%Y %m/%d %p %I:%M")
                                if download_date.month == 12 and start_date.month == 1:
                                    start_date = datetime.datetime.strptime("%d %s" % (download_date.year + 1, match_program.group(3)), "%Y %m/%d %p %I:%M")
                                dic_programme["programme_start"] = start_date.strftime("%Y%m%d%H%M")
                                end_date = datetime.datetime.strptime("%d %s" % (download_date.year, match_program.group(4)), "%Y %m/%d %p %I:%M")
                                if download_date.month == 12 and end_date.month == 1:
                                    end_date = datetime.datetime.strptime("%d %s" % (download_date.year + 1, match_program.group(4)), "%Y %m/%d %p %I:%M")
                                dic_programme["programme_stop"] = end_date.strftime("%Y%m%d%H%M")
                                end = match_program.group(4)
                                dic_programme["category"] = match_program.group(5).split("-")[0]

                                generateXmlProgramme(dic_programme)

                    f.close()

                    progress += checkchannel_count
                    progressLog(progress, len(channel_config) * retrieve_days)

                checkchannel = ""
                checkchannel_count = 0
    printLog("==> Done.", end = "\n\n")

def generateXmlProgrammeEveryOnTV():
    channel_config = [[k, v] for k, v in channel_list if v[0] == "O"]
    if len(channel_config) <= 0:
        return

    generate_source = "http://www.everyon.tv/"
    base_url = "http://www.everyon.tv/main/schedule.etv?chNum={channel_code}&schDt={date_ymd}"

    printLog("==> Generate Programmes (EvenryOnTV)")
    progress = 0
    progressLog(0, len(channel_config) * retrieve_days)

    for channel in channel_config:
        channel_id = channel[0].split(",")[0]
        channel_name = channel[0].split(",")[1]
        channel_code = channel[1].split(",")[3]

        dic_programme = {}

        for day in range(retrieve_days):
            download_date = (datetime.date.today() + datetime.timedelta(days = day))
            url = base_url.replace("{channel_code}", channel_code).replace("{date_ymd}", download_date.strftime("%Y%m%d"))

            #with request.urlopen(url) as f:
            f = None
            try:
                f = request.urlopen(url)
            except Exception as e:
                printLog(" -> error : %s (EveryOnTV) - %s" % (url, e.args[0]), error = True)
                continue
            html = f.read().decode("utf8", "ignore")
            if __USE_BS:
                if __USE_LXML:
                    soup = BeautifulSoup(html, "lxml")
                else:
                    soup = BeautifulSoup(html, "html.parser")
                for tr in soup.select("tbody tr"):
                    row = 0
                    for td in tr.find_all("td"):
                        if row == 0:
                            if dic_programme:
                                if "programme_start" in dic_programme and "programme_stop" in dic_programme:
                                    generateXmlProgramme(dic_programme)

                            dic_programme.clear()
                            dic_programme["channel_id"] = channel_id
                            dic_programme["channel_name"] = channel_name
                            dic_programme["generate_source"] = generate_source
                            match_time = re.search("^(.*):(.*)~(.*):(.*)$", td.next_element.strip())
                            if match_time:
                                dic_programme["programme_start"] = "%s%s%s" % (download_date.strftime("%Y%m%d"), match_time.group(1), match_time.group(2))
                                dic_programme["programme_stop"] = "%s%s%s" % (download_date.strftime("%Y%m%d"), match_time.group(3), match_time.group(4))
                        elif row == 1:
                            match_episode_num = re.search("^(.*)[\(|\[|<| ]([\d|,]+[회|강|부])[\)|\]|>| ]?$", td.next_element.strip())
                            if match_episode_num:
                                dic_programme["title"] = "%s (%s)" % (match_episode_num.group(1).strip(), match_episode_num.group(2).strip())
                                dic_programme["episode_num"] = match_episode_num.group(2).strip()
                            else:
                                dic_programme["title"] = td.next_element.strip()
                            #dic_programme["sub_title"] = dic_programme["title"]
                            #dic_programme["desc"] = dic_programme["title"]
                        elif row == 2:
                            dic_programme["rating"] = td.next_element.strip()
                        row += 1
            else:
                body = html.partition("<tbody>")[2].rpartition("</tbody>")[0]
                for programme in body.split("<tr>"):
                    match = re.search(".*<td>(\d+):(\d+)~(\d+):(\d+)<\/td>.*<td>(.*)<\/td>.*<td>(.*)<\/td>.*<\/tr>", programme, re.MULTILINE | re.DOTALL)
                    if match:
                        if dic_programme:
                            if "programme_start" in dic_programme and "programme_stop" in dic_programme:
                                generateXmlProgramme(dic_programme)

                        dic_programme.clear()
                        dic_programme["channel_id"] = channel_id
                        dic_programme["channel_name"] = channel_name
                        dic_programme["generate_source"] = generate_source
                        dic_programme["programme_start"] = "%s%s%s" % (download_date.strftime("%Y%m%d"), match.group(1), match.group(2))
                        dic_programme["programme_stop"] = "%s%s%s" % (download_date.strftime("%Y%m%d"), match.group(3), match.group(4))
                        match_episode_num = re.search("^(.*)[\(|\[|<| ]([\d|,]+[회|강|부])[\)|\]|>| ]?$", match.group(5).strip())
                        if match_episode_num:
                            dic_programme["title"] = "%s (%s)" % (match_episode_num.group(1).strip(), match_episode_num.group(2).strip())
                            dic_programme["episode_num"] = match_episode_num.group(2).strip()
                        else:
                            dic_programme["title"] = match.group(5).strip()
                        #dic_programme["sub_title"] = dic_programme["title"]
                        #dic_programme["desc"] = dic_programme["title"]
                        dic_programme["rating"] = match.group(6)

            f.close()
            progress += 1
            progressLog(progress, len(channel_config) * retrieve_days)

    printLog("==> Done.", end = "\n\n")

def getCategory(category):
    if category == "드라마":
        category_ko = category
        category_en = "Movie / Drama"
    elif category == "영화":
        category_ko = category
        category_en = "Movie / Drama"
    elif category == "만화":
        category_ko = category
        category_en = "Children's / Youth programmes"
    elif category == "연예/오락":
        category_ko = category
        category_en = "Show / Games"
    elif category == "스포츠":
        category_ko = category
        category_en = "Sports"
    elif category == "라이프":
        category_ko = category
        category_en = "Leisure hobbies"
    elif category == "공연/음악":
        category_ko = category
        category_en = "Music / Ballet / Dance"
    elif category == "교육":
        category_ko = category
        category_en = "Education / Science / Factual topics"
    elif category == "뉴스/정보":
        category_ko = category
        category_en = "News / Current affairs"
    elif category == "다큐":
        category_ko = category
        category_en = "Social / Political issues / Economics"
    elif category == "예술":
        category_ko = category
        category_en = "Arts / Culture (without music)"
    elif category == "A":
        category_ko = "드라마"
        category_en = "Movie / Drama"
    elif category == "B":
        category_ko = "영화"
        category_en = "Movie / Drama"
    elif category == "C":
        category_ko = "만화"
        category_en = "Children's / Youth programmes"
    elif category == "D":
        category_ko = "연예/오락"
        category_en = "Show / Games"
    elif category == "E":
        category_ko = "스포츠"
        category_en = "Sports"
    elif category == "F":
        category_ko = "취미/레저"
        category_en = "Leisure hobbies"
    elif category == "G":
        category_ko = "음악"
        category_en = "Music / Ballet / Dance"
    elif category == "H":
        category_ko = "교육"
        category_en = "Education / Science / Factual topics"
    elif category == "I":
        category_ko = "뉴스"
        category_en = "News / Current affairs"
    elif category == "J":
        category_ko = "시사/다큐"
        category_en = "Social / Political issues / Economics"
    elif category == "K":
        category_ko = "교양/정보"
        category_en = "Arts / Culture (without music)"
    elif category == "L":
        category_ko = "홈쇼핑"
        category_en = ""
    elif category == "시사/다큐":
        category_ko = category
        category_en = "Social / Political issues / Economics"
    elif category == "교양/정보":
        category_ko = category
        category_en = "Arts / Culture (without music)"
    elif category == "홈쇼핑":
        category_ko = category
        category_en = ""
    else:
        category_ko = ""
        category_en = ""

    return category_ko, category_en

def postProc():
    if post_proc and os.path.exists(post_proc):
        match_post_proc = re.match("^\w.*$", post_proc)
        if match_post_proc:
            call(["./%s" % post_proc, post_proc_args])
        else:
            call([post_proc, post_proc_args])

def generateChannelListUplus(o):
    printLog("==> Generate Channel List (Uplus)")
    total = 0
    printLog("##LG유플러스", file = o)
    printLog("#http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvSchedule.hpi?chnlCd={channelId}&evntCmpYmd=YYYYMMDD", file = o)
    printLog("#channelId,channelName", file = o)
    #with urllib.request.urlopen("http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvContentsMFamily.hpi") as f:
    f = None
    try:
        f = request.urlopen("http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvContentsMFamily.hpi", timeout=10)
    except socket.timeout as e:
        printLog(" -> socket.timeout : %s" % e.args[0], error = True)
    except urllib.error.URLError:
        printLog(" -> URLerror : %s" % e.args[0], error = True)

    if f is None:
        printLog("")
        return

    html = f.read().decode("cp949", "ignore")
    if __USE_LXML:
        soup = BeautifulSoup(html, "lxml")
    else:
        soup = BeautifulSoup(html, "html.parser")
    for a in soup.select('a[href]'):
        if a['href'] == '#CHANNEL':
            result = []
            printLog("#LG유플러스 %s" % a.text, file = o)
            match = re.match(".*\('(.*)','(.*)','.*','.*'\).*", a['onclick'])
            if match:
                #with urllib.request.urlopen("http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvChannel.hpi?code=%s&category=%s" % (match.group(2), match.group(1))) as f2:
                f2 = None
                try:
                    f2 = request.urlopen("http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvChannel.hpi?code=%s&category=%s" % (match.group(2), match.group(1)))
                except:
                    continue
                html2 = f2.read().decode("cp949", "ignore")
                if __USE_LXML:
                    soup2 = BeautifulSoup(html2, "lxml")
                else:
                    soup2 = BeautifulSoup(html2, "html.parser")
                for b in soup2.select('a[href]'):
                    if b['href'] == '#':
                        match2 = re.match(".*retrieveSchedule\('(.*)','.*'\).*", b['onclick'])
                        if match2:
                            #match_b_text = re.match("^(.*)\(Ch\.\d+\)$", b.text)
                            #if match_b_text:
                            #    printLog("U,%s,%s" % (match2.group(1), match_b_text.group(1)), file = o)
                            #else:
                            #    printLog("U,%s,%s" % (match2.group(1), b.text), file = o)
                            #printLog("U,%s,%s" % (match2.group(1), b.text), file = o)
                            result.append("U,%s,%s" % (match2.group(1), b.text))
                            total += 1
                            progressCount(total)
                f2.close()
                result = list(set(result))
                result.sort()
                printLog("\n".join(result), file = o)
    f.close()
    printLog("", file = o)
    printLog("")
    printLog("==> Done.", end = "\n\n")

def generateChannelListSKB(o):
    printLog("==> Generate Channel List (SKB)")
    total = 0
    printLog("##SKB", file = o)
    printLog("#http://m.skbroadband.com/content/realtime/Channel_List.do?key_depth1={key_depth1}&key_depth2={key_depth2}&key_depth3=YYYYMMDD", file = o)
    printLog("#key_depth1,key_depth2,channel_name", file = o)
    html = ""

    try:
        conn = http.client.HTTPConnection("m.skbroadband.com", 80)
        conn.request("GET", "/content/realtime/Channel_List.do")
        f = conn.getresponse()
        html = f.read().decode("cp949", "ignore")
        conn.close()
    except socket.timeout as e:
        printLog(" -> socket.timeout : %s" % e.args[0], error = True)
    except urllib.error.URLError:
        printLog(" -> URLerror : %s" % e.args[0], error = True)

    if f is None:
        printLog("")
        return

    if __USE_LXML:
        soup = BeautifulSoup(html, "lxml")
    else:
        soup = BeautifulSoup(html, "html.parser")
    for a in soup.select('li[onclick]'):
        if a['onclick'] == 'test(this.value);':
            result = []
            printLog("#SKB %s" % a.text.replace("선택됨", ""), file = o)

            html2 = ""
            try:
                conn2 = http.client.HTTPConnection("m.skbroadband.com", 80)
                conn2.request("GET", "/content/realtime/Channel_List.do?key_depth1=%s" % a['value'])
                f2 = conn2.getresponse()
                html2 = f2.read().decode("cp949", "ignore")
                conn2.close()
            except:
                continue

            if __USE_LXML:
                soup2 = BeautifulSoup(html2, "lxml")
            else:
                soup2 = BeautifulSoup(html2, "html.parser")
            for b in soup2.select('select[id=channel] option'):
                    result.append("S,%s,%s,%s" % (a['value'], b['value'], b.text))
                    total += 1
                    progressCount(total)
            f2.close()
            result = list(set(result))
            result.sort()
            printLog("\n".join(result), file = o)
    f.close()
    printLog("", file = o)
    printLog("")
    printLog("==> Done.", end = "\n\n")


#Deprecated
def generateChannelListNaver(o):
    printLog("==> Generate Channel List (Naver)")
    total = 0
    printLog("##네이버", file = o)
    printLog("#https://search.naver.com/search.naver?query={channelCode}", file = o)
    printLog("#channelCode,channelName", file = o)
    #with urllib.request.urlopen("https://search.naver.com/search.naver?query=" + quote("편성표")) as f:
    f = None
    try:
        f = request.urlopen("https://search.naver.com/search.naver?query=" + quote("편성표"))
    except:
        printLog("", file = o)
        printLog("==> Error.", end = "\n\n")
        return
    html = f.read().decode("utf-8", "ignore")

    if __USE_LXML:
        soup = BeautifulSoup(html, "lxml")
    else:
        soup = BeautifulSoup(html, "html.parser")

    for a in soup.select('div[class=cs_tvtime] div[class=cs_tab] a[href]'):
        if a.text != "케이블" and a.text != "스카이라이프":
            printLog("#네이버 %s" % (a.text), file = o)

        f2 = None
        try:
            f2 = request.urlopen("https://search.naver.com/search.naver?" + a['href'])
        except HTTPError:
            continue

        html2 = f2.read().decode("utf-8", "ignore")

        if __USE_LXML:
            soup2 = BeautifulSoup(html2, "lxml")
        else:
            soup2 = BeautifulSoup(html2, "html.parser")
        result = []
        for a2 in soup2.select('div[class=cs_tvtime] div[class=cont_area] a[href]'):
            if a.text == "케이블" and (a2.text == "드라마" or a2.text == "영화" or a2.text == "연예/오락" or a2.text == "스포츠/게임" or a2.text == "어린이" or a2.text == "쇼핑" or a2.text == "뉴스/경제" or a2.text == "레저" or a2.text == "여성/패션" or a2.text == "해외" or a2.text == "종교" or a2.text == "공공" or a2.text == "교육" or a2.text == "다큐" or a2.text == "교양/정보"):
                if result:
                    result = list(set(result))
                    result.sort()
                    printLog("\n".join(result), file = o)
                    result.clear()
                printLog("#네이버 %s %s" % (a.text, a2.text), file = o)
            elif a.text == "스카이라이프" and (a2.text == "지상파" or a2.text == "종합편성" or a2.text == "드라마" or a2.text == "영화" or a2.text == "연예/오락" or a2.text == "스포츠/게임" or a2.text == "어린이" or a2.text == "쇼핑" or a2.text == "뉴스/경제" or a2.text == "레저" or a2.text == "여성/패션" or a2.text == "해외" or a2.text == "종교" or a2.text == "공공/정보" or a2.text == "교육" or a2.text == "다큐"):
                if result:
                    result = list(set(result))
                    result.sort()
                    printLog("\n".join(result), file = o)
                    result.clear()

                printLog("#네이버 %s %s" % (a.text, a2.text), file = o)
            else:
                match_href = re.match("^.*query=(.*)$", a2['href'])
                if match_href:
                    #printLog("N,%s,%s" % (unquote(match_href.group(1)), a2.text), file = o)
                    result.append("N,%s,%s" % (unquote(match_href.group(1)), a2.text))
                else:
                    #printLog("N,%s,%s" % (a2.text, a2.text), file = o)
                    result.append("N,%s,%s" % (a2.text, a2.text))
                total += 1
                progressCount(total)

        f2.close()

        if result:
            result = list(set(result))
            result.sort()
            printLog("\n".join(result), file = o)
            result.clear()

    f.close()
    printLog("", file = o)
    printLog("")
    printLog("==> Done.", end = "\n\n")

#Deprecated
def generateChannelListEpg(o):
    printLog("==> Generate Channel List (EPG)")
    total = 0
    printLog("##EPG", file = o)
    printLog("#http://www.epg.co.kr/new/tvguide/tvguide.php?search_top_channel_group={search_top_channel_group}&old_top_channel_group={search_top_channel_group}&search_sub_channel_group={search_sub_channel_group}&old_sub_channel_group={search_sub_channel_group}&ymd={date}&{channel}", file = o)
    printLog("#top_channel_group,sub_channel_group,checkchannel,channel_name", file = o)
    #with urllib.request.urlopen("http://epg.co.kr/php/guide/schedule_day_on.php") as f:
    f = None
    try:
        f = request.urlopen("http://epg.co.kr/php/guide/schedule_day_on.php")
    except:
        printLog("", file = o)
        printLog("==> Error.", end = "\n\n")
        return
        
    html = f.read().decode("cp949", "ignore")
    soup = BeautifulSoup(html, "lxml")
    for a in soup.select('select[name=search_top_channel_group] option'):
        if 'selected' in a.attrs:
            top_channel_group = ""
            sub_channel_group = ""
            printLog("#EPG %s" % a.text, file = o)
            result = []
            for b in soup.select('input[name=search_top_channel_group]'):
                if 'value' in b.attrs:
                    top_channel_group = b['value']
                    break
            for b in soup.select('input[name=search_sub_channel_group]'):
                if 'value' in b.attrs:
                    sub_channel_group = b['value']
                    break
            for b in soup.select('input[name^=checkchannel]'):
                if b['type'] == "checkbox":
                    match_b_value = re.match("^(.*)\(\d+\)$", b['value'])
                    if match_b_value:
                        #printLog("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, b['name'].replace('checkchannel[', '').replace(']', ''), match_b_value.group(1)), file = o)
                        result.append("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, b['name'].replace('checkchannel[', '').replace(']', ''), match_b_value.group(1)))
                    else:
                        #printLog("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, b['name'].replace('checkchannel[', '').replace(']', ''), b['value']), file = o)
                        result.append("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, b['name'].replace('checkchannel[', '').replace(']', ''), b['value']))
                    total += 1
                    progressCount(total)
            result = list(set(result))
            result.sort()
            printLog("\n".join(result), file = o)
        else:
            #with urllib.request.urlopen("http://epg.co.kr/php/guide/schedule_day_on.php?search_top_channel_group=%s" % a['value']) as f2:
            f2 = None
            try:
                f2 = request.urlopen("http://epg.co.kr/php/guide/schedule_day_on.php?search_top_channel_group=%s" % a['value'])
            except:
                continue
            html2 = f2.read().decode("cp949", "ignore")
            soup2 = BeautifulSoup(html2, "lxml")
            for b in soup2.select('select[name=search_sub_channel_group] option'):
                if b['value'] == '':
                    continue
                if 'selected' in b.attrs:
                    top_channel_group = ""
                    sub_channel_group = ""
                    printLog("#EPG %s %s" % (a.text, b.text), file = o)
                    result = []
                    for c in soup2.select('input[name=search_top_channel_group]'):
                        if 'value' in c.attrs:
                            top_channel_group = c['value']
                            break
                    for c in soup2.select('input[name=search_sub_channel_group]'):
                        if 'value' in c.attrs:
                            sub_channel_group = c['value']
                            break
                    for c in soup2.select('input[name^=checkchannel]'):
                        if c['type'] == "checkbox":
                            match_c_value = re.match("^(.*)\(\d+\)$", c['value'])
                            if match_c_value:
                                #printLog("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, c['name'].replace('checkchannel[', '').replace(']', ''), match_c_value.group(1)), file = o)
                                result.append("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, c['name'].replace('checkchannel[', '').replace(']', ''), match_c_value.group(1)))
                            else:
                                #printLog("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, c['name'].replace('checkchannel[', '').replace(']', ''), c['value']), file = o)
                                result.append("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, c['name'].replace('checkchannel[', '').replace(']', ''), c['value']))
                            total += 1
                            progressCount(total)
                    result = list(set(result))
                    result.sort()
                    printLog("\n".join(result), file = o)
                else:
                    #with urllib.request.urlopen("http://epg.co.kr/php/guide/schedule_day_on.php?search_top_channel_group=%s&old_top_channel_group=%s&search_sub_channel_group=%s&old_sub_channel_group=%s" % (a['value'], a['value'], b['value'], b['value'])) as f3:
                    f3 = None
                    try:
                        f3 = request.urlopen("http://epg.co.kr/php/guide/schedule_day_on.php?search_top_channel_group=%s&old_top_channel_group=%s&search_sub_channel_group=%s&old_sub_channel_group=%s" % (a['value'], a['value'], b['value'], b['value']))
                    except:
                        continue
                    html3 = f3.read().decode("cp949", "ignore")
                    soup3 = BeautifulSoup(html3, "lxml")
                    top_channel_group = a['value']
                    sub_channel_group = b['value']
                    printLog("#EPG %s %s" % (a.text, b.text), file = o)
                    result = []
                    for d in soup3.select('input[name^=checkchannel]'):
                        if d['type'] == "checkbox":
                            match_d_value = re.match("^(.*)\(\d+\)$", d['value'])
                            if match_d_value:
                                #printLog("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, d['name'].replace('checkchannel[', '').replace(']', ''), match_d_value.group(1)), file = o)
                                result.append("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, d['name'].replace('checkchannel[', '').replace(']', ''), match_d_value.group(1)))
                            else:
                                #printLog("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, d['name'].replace('checkchannel[', '').replace(']', ''), d['value']), file = o)
                                result.append("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, d['name'].replace('checkchannel[', '').replace(']', ''), d['value']))
                            total += 1
                            progressCount(total)
                    result = list(set(result))
                    result.sort()
                    printLog("\n".join(result), file = o)
                    f3.close()
            f2.close()
    f.close()

    printLog("", file = o)
    printLog("")
    printLog("==> Done.", end = "\n\n")

def generateChannelList():
    with open(LIST_FILE, "w", encoding='utf8') as f:
        o = []
        o.append(f)
        if args.v:
            o.append(sys.stderr)

        generateChannelListUplus(o)
        generateChannelListSKB(o)
        #generateChannelListNaver(o)
        #generateChannelListEpg(o)

def checkChannelList():
    printLog("==> Check Channels")

    progress = 0;
    progressLog(0, len(channel_list))

    list_file = []

    if os.path.isfile(LIST_FILE):
        with open(LIST_FILE, "r") as f:
            line = f.readline()
            while line:
                if not line == "" and not line == "\n" and not line.startswith("#"):
                    list_file.append(line.rstrip())
                line = f.readline()

    if os.path.isfile(LIST_FILE_STATIC):
        with open(LIST_FILE_STATIC, "r") as f_static:
            line_static = f_static.readline()
            while line_static:
                if not line_static == "" and not line_static == "\n" and not line_static.startswith("#"):
                    list_file.append(line_static.rstrip())
                line_static = f_static.readline()

    for channel_config in channel_list:
        if not channel_config[1] in list_file:
            match = re.match("(.*),[^,]*", channel_config[1])
            if match:
                conf = match.group(1)
                print(conf)
                conf_match = [k for k in list_file if k.startswith(conf)]
                if conf_match:
                    printLog("")
                    printLog(" -> Changed : [%s] to [%s]" % (channel_config[1], conf_match[0]))
                else:
                    printLog("")
                    printLog(" -> Unknown source : [%s]" % channel_config[1])
            else:
                printLog("")
                printLog(" -> Invalid : [%s]" % channel_config[1])

        progress += 1
        progressLog(progress, len(channel_list))

    printLog("==> Done.", end = "\n\n")

if __name__ == '__main__':
    argumentParser = argparse.ArgumentParser()
    argumentParser.add_argument("-v", "--v", action="store_true", help="verbose")
    argumentParser.add_argument("-b", "--b", action="store_true", help="pretty_print")
    argumentParser.add_argument("-g", "--g", action="store_true", help="generate_list")
    argumentParser.add_argument("-c", "--c", action="store_true", help="check_channel")
    argumentParser.add_argument("-s", "--s", action="store_true", help="socket_write")
    argumentParser.add_argument("-f", "--f", help="config_file")
    args = argumentParser.parse_args()

    if not __USE_BS:
        printLog("BeautifulSoup4를 찾을 수 없습니다.")
        exit(1)

    if args.g:
        if not __USE_BS:
            printLog("채널 소스 생성은 BeautifulSoup4가 필요합니다.")
            exit(1)
        generateChannelList()

    elif args.c:
        readConfig()

        checkChannelList()

    elif args.s:
        readConfig()

        writeSocket()

    else:
        readConfig()

        generateXmlRoot()

        generateXmlChannel()

        generateXmlProgrammeUplus()

        generateXmlProgrammeSKB()

        #generateXmlProgrammeNaver()

        #generateXmlProgrammeEpg()

        generateXmlProgrammeEveryOnTV()

        writeXml()
        postProc()

        if args.v:
            printXml()

    printLog("==> Execution time : %.2fs" % (time.time() - ___START_TIME))

